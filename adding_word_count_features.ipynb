{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting display options to maximum in order to display all columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "# disable chained assignment warnings\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# maximize display width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_metrics(df, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate amount of words, word length and .\n",
    "    \n",
    "    Arguments:\n",
    "    df_column      (obj): Pandas dataframe column as Series\n",
    "    \n",
    "    Returns:\n",
    "    tuple\n",
    "    \n",
    "    \"\"\"\n",
    "    # Replace all non letter characters with a whitespace\n",
    "    df['text_clean_'+column] = df[column].str.replace('[^a-zA-Z]', ' ')\n",
    "    # Change to lower case\n",
    "    df['text_clean_'+column] = df['text_clean_'+column].str.lower()\n",
    "    # Print the first 5 rows of the text_clean column\n",
    "    print(df['text_clean_'+column].head())\n",
    "\n",
    "    # Find the length of each text\n",
    "    df['char_cnt_'+column] = df['text_clean_'+column].str.len()\n",
    "    # Count the number of words in each text\n",
    "    df['word_cnt_'+column] = df['text_clean_'+column].str.split().str.len()\n",
    "    # Find the average length of word\n",
    "    df['avg_word_length_'+column] = df['char_cnt_'+column] / df['word_cnt_'+column]\n",
    "    # Print the first 5 rows of these columns\n",
    "    print(df[['text_clean_'+column, 'char_cnt_'+column, 'word_cnt_'+column, 'avg_word_length_'+column]])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume DataFrame exists as variable df, removal due to privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with few variables\n",
    "cols_to_drop = ['index','observer','shift','risk_area','len_descr','control_doc','loss_potential_comments','suggestion','contact_person','comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get rid of the cols\n",
    "df.drop(labels=cols_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58836, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "## Add word metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform for description field\n",
    "df_description_metrics = generate_word_metrics(df, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58836, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding clustered LDA topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirpath_nlp contains the created LDA categorical features (e.g. 3 for an incident being assigned to topic 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_dominant_topics = pd.read_csv(dirpath_nlp+'/topics_sentences_descr_four.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110764, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_dominant_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>vessel, lift, oper, crew, team, crane, deck, drill, transfer, technician</td>\n",
       "      <td>['whilst', 'bullbai', 'push', 'push', 'tube', 'central', 'fender', 'loos', 'free', 'main', 'fender', 'hous', 'deckhand', 'inform', 'master', 'push', 'seiz', 'immedi', 'bullbai', 'report', 'damag', 'site', 'manag', 'agre', 'bullbai', 'head', 'ashor', 'damag', 'assess', 'drop', 'equip', 'regina', 'baltica', 'transfer', 'equip', 'regina', 'baltica', 'readi', 'damag', 'fender', 'came', 'complet', 'free', 'hous', 'drop', 'water', 'equip', 'transfer', 'safe', 'bullbai', 'proceed', 'shore', 'fender', 'retriev', 'vessel', 'oshor', 'bullbai']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0  0            2.0             0.8831               \n",
       "\n",
       "                                                                   Keywords  \\\n",
       "0  vessel, lift, oper, crew, team, crane, deck, drill, transfer, technician   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Text  \n",
       "0  ['whilst', 'bullbai', 'push', 'push', 'tube', 'central', 'fender', 'loos', 'free', 'main', 'fender', 'hous', 'deckhand', 'inform', 'master', 'push', 'seiz', 'immedi', 'bullbai', 'report', 'damag', 'site', 'manag', 'agre', 'bullbai', 'head', 'ashor', 'damag', 'assess', 'drop', 'equip', 'regina', 'baltica', 'transfer', 'equip', 'regina', 'baltica', 'readi', 'damag', 'fender', 'came', 'complet', 'free', 'hous', 'drop', 'water', 'equip', 'transfer', 'safe', 'bullbai', 'proceed', 'shore', 'fender', 'retriev', 'vessel', 'oshor', 'bullbai']  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_dominant_topics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume another dataframe with more observations, df_110, has been added.\n",
    "merged_dominant_topics = pd.merge(df_110, nlp_dominant_topics, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110764, 41)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dominant_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting to only incidents with these three application numbers\n",
    "incidents = merged_dominant_topics[merged_dominant_topics['application'].isin([20, 21, 22])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58836, 41)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_word_metrics['text_preprocessed_word_cnt'] = incidents_word_metrics['Text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'observer',\n",
       " 'shift',\n",
       " 'risk_area',\n",
       " 'len_descr',\n",
       " 'control_doc',\n",
       " 'loss_potential_comments',\n",
       " 'suggestion',\n",
       " 'contact_person',\n",
       " 'comments']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_word_metrics.drop(labels=cols_to_drop, axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58836, 37)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidents_word_metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_word_metrics.to_csv('incidents_with_word_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}