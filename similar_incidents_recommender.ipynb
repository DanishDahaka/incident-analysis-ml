{
 "cells": [
  {
   "source": [
    "# Example proof of concept for a recommender system based on text similarity between incidents"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Adapted after (main credit goes to): https://www.datacamp.com/community/tutorials/recommender-systems-python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# progress bar\n",
    "from tqdm.auto import tqdm  # for notebooks"
   ]
  },
  {
   "source": [
    "### necessary downloads before using nltk locally"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    \n",
    "    \"\"\" lowercase and tokenize text, keep only alphabetical cahrs \n",
    "\n",
    "    Args: \n",
    "        text            (string):      text to clean\n",
    "\n",
    "    Returns:\n",
    "        text            (string):      cleaned text\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    text = str(text).lower()\n",
    "    # adding numbers to regex, possibly information like \"BKR01\" as location is helpful\n",
    "    text = re.sub('[^A-Za-z0-9]', ' ', text)\n",
    "    text = word_tokenize(text)\n",
    "    text = [token for token in text if token not in stopwords.words('english')]\n",
    "    \n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mention_in_document(stri, text):\n",
    "    \n",
    "    \"\"\"Return true if (sub-)string in text\n",
    "\n",
    "    Args: \n",
    "        stri          (string):   string to search for\n",
    "        text          (string):   text in which is searched\n",
    "\n",
    "    Returns:\n",
    "        bool\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # check inside list\n",
    "    if stri in text:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_column_to_cosine_sim(df, column):\n",
    "\n",
    "    \"\"\"Creates cosine similarity for each document in a dataframe. \n",
    "\n",
    "    Args: \n",
    "        df              (obj):      DataFrame\n",
    "        column          (string):   Name of the column\n",
    "\n",
    "    Returns:\n",
    "        corpus          (list):     list of documents as strings\n",
    "        tf_idf_matrix   (obj):      scipy sparse tf-idf matrix\n",
    "        cosine_sim      (array):    cosine similarity matrix\n",
    "\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # convert dataframe strings into list of strings\n",
    "    corpus = df[column].tolist()\n",
    "    \n",
    "    # use english stop words\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # generate tf-idf vectors for corpus\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # compute similarity matrix with pairwise scores, faster version\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    # get total time\n",
    "    print('Time taken is {} seconds'.format(round(end-start,4)))\n",
    "    \n",
    "    \n",
    "    return corpus, tfidf_matrix, cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim, df, column, top_n):\n",
    "\n",
    "    \"\"\"Create item recommendations based on cosine similarity\n",
    "\n",
    "    Args: \n",
    "        title           (string):   Item name\n",
    "        cosine_sim      (array):    cosine similarity matrix\n",
    "        df              (obj):      DataFrame\n",
    "        column          (string):   Column name\n",
    "        top_n           (int):      amount of similar observations\n",
    "\n",
    "    Returns:\n",
    "        df              (obj):      DataFrame with top_n recommendations\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # check input value for top_n to be smaller than 20\n",
    "    try:\n",
    "        assert top_n < 20\n",
    "    except:\n",
    "        raise ValueError('Too high value for top_n. Enter less than 20.')\n",
    "    \n",
    "\n",
    "    # adjust index for searching\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Generate mapping between titles and index\n",
    "    indices = pd.Series(df.index, index=df[column])\n",
    "\n",
    "    # Get index of item that matches title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Sort the items based on the similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores for n most similar items\n",
    "    sim_scores = sim_scores[1:top_n]\n",
    "\n",
    "    # Get the item indices\n",
    "    item_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top n most similar items\n",
    "    return df[column].iloc[item_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read in data and check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>case_no</th>\n",
       "      <th>trans</th>\n",
       "      <th>calenday_day</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>observer</th>\n",
       "      <th>shift</th>\n",
       "      <th>comments</th>\n",
       "      <th>len_descr</th>\n",
       "      <th>...</th>\n",
       "      <th>actual_hazard</th>\n",
       "      <th>process</th>\n",
       "      <th>product</th>\n",
       "      <th>control_doc</th>\n",
       "      <th>causes_descr</th>\n",
       "      <th>suggestion</th>\n",
       "      <th>audit_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>location_description</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93038</td>\n",
       "      <td>539254</td>\n",
       "      <td>2015-05-04 09:30:00</td>\n",
       "      <td>BKR01 - Bullbay fender damaged during push on ...</td>\n",
       "      <td>Whilst the bullbay was pushed on to Q05 push o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Vessel fender had been altered to suit require...</td>\n",
       "      <td>PC - The section of the fender which was damag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Germany - _Projects/Construction sites - Proje...</td>\n",
       "      <td>-- Not selected --</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  case_no   trans         calenday_day  \\\n",
       "0      0    93038  539254  2015-05-04 09:30:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  BKR01 - Bullbay fender damaged during push on ...   \n",
       "\n",
       "                                         description  observer  shift  \\\n",
       "0  Whilst the bullbay was pushed on to Q05 push o...         0      0   \n",
       "\n",
       "  comments  len_descr  ...  actual_hazard process product  control_doc  \\\n",
       "0      NaN        732  ...            0.0     0.0     0.0          0.0   \n",
       "\n",
       "                                        causes_descr  \\\n",
       "0  Vessel fender had been altered to suit require...   \n",
       "\n",
       "                                          suggestion  audit_type  diagnosis  \\\n",
       "0  PC - The section of the fender which was damag...         0.0        2.0   \n",
       "\n",
       "                                location_description  product_description  \n",
       "0  Germany - _Projects/Construction sites - Proje...   -- Not selected --  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['trans','index','contact_person','comments','loss_potential_comments','observer','shift','risk_area','control_doc', 'start_date', 'end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=cols_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40654, 26)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Clean title text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dd9a8d9e0343eb97e01a55825a9655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40654.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken is 80.4146 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "df['title_cleaned'] = df['title'].progress_apply(lambda x: cleaner(str(x)))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# get total time\n",
    "print('Time taken is {} seconds'.format(round(end-start,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Investigate amount of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_push'] = df['title_cleaned'].apply(lambda x: check_mention_in_document('push', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of mentions is 149 which is 0.0037 per cent\n"
     ]
    }
   ],
   "source": [
    "print('amount of mentions is {} which is {} per cent'.format(df['title_push'].sum(), round(df['title_push'].sum()/len(df),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_values = ['vessel', 'water','wave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in title_values:\n",
    "    df['title_'+value] = df['title_cleaned'].apply(lambda x: check_mention_in_document(value, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vessel: 1623\n",
      "water: 897\n",
      "wave: 87\n"
     ]
    }
   ],
   "source": [
    "for value in title_values:\n",
    "    print(value+':', df['title_'+value].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example recommendations based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose column to index\n",
    "column = 'title_cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is 5.1998 seconds\n"
     ]
    }
   ],
   "source": [
    "# prepare text, store returned variables\n",
    "title_corpus, title_tfidf_matrix, title_cosine_sim = dataframe_column_to_cosine_sim(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bkr01 bullbay fender damaged push operations location q05\n"
     ]
    }
   ],
   "source": [
    "# print cleaned title for first case\n",
    "test_title = df.iloc[0,-5]\n",
    "\n",
    "print(test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21314                                          push system\n",
      "15302                               seized door handle q05\n",
      "15589                                   damaged push tubes\n",
      "35324                             crane damaged operations\n",
      "26395    bkr01 crew transfer vessel largo push fender s...\n",
      "171        damage vessel fender boat landing push tube a01\n",
      "13744            bkr01 beaumaris bay fender poor condition\n",
      "14162                        c wind artimus damaged fender\n",
      "5677                                           push lights\n",
      "Name: title_cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(get_recommendations(test_title, title_cosine_sim,\n",
    "                          df, column, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}